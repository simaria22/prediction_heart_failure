{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6cbed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee611315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93e8435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc89f897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'folders': [{'path': '.'}], 'settings': {}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2eb456a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3f46ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869df998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****start of feature  age *************************\n",
      "60.000    33\n",
      "50.000    27\n",
      "65.000    26\n",
      "70.000    25\n",
      "45.000    19\n",
      "55.000    17\n",
      "75.000    11\n",
      "53.000    10\n",
      "58.000    10\n",
      "63.000     8\n",
      "80.000     7\n",
      "72.000     7\n",
      "40.000     7\n",
      "42.000     7\n",
      "85.000     6\n",
      "68.000     5\n",
      "52.000     5\n",
      "62.000     5\n",
      "51.000     4\n",
      "59.000     4\n",
      "61.000     4\n",
      "73.000     4\n",
      "49.000     4\n",
      "69.000     3\n",
      "46.000     3\n",
      "64.000     3\n",
      "82.000     3\n",
      "90.000     3\n",
      "78.000     2\n",
      "60.667     2\n",
      "54.000     2\n",
      "77.000     2\n",
      "57.000     2\n",
      "66.000     2\n",
      "44.000     2\n",
      "67.000     2\n",
      "95.000     2\n",
      "48.000     2\n",
      "43.000     1\n",
      "86.000     1\n",
      "81.000     1\n",
      "79.000     1\n",
      "41.000     1\n",
      "94.000     1\n",
      "87.000     1\n",
      "47.000     1\n",
      "56.000     1\n",
      "Name: age, dtype: int64\n",
      "*****end of feature  age ************************** \n",
      "\n",
      "*****start of feature  anaemia *************************\n",
      "0    170\n",
      "1    129\n",
      "Name: anaemia, dtype: int64\n",
      "*****end of feature  anaemia ************************** \n",
      "\n",
      "*****start of feature  creatinine_phosphokinase *************************\n",
      "582     47\n",
      "66       4\n",
      "129      4\n",
      "231      3\n",
      "69       3\n",
      "        ..\n",
      "748      1\n",
      "1876     1\n",
      "936      1\n",
      "292      1\n",
      "2413     1\n",
      "Name: creatinine_phosphokinase, Length: 208, dtype: int64\n",
      "*****end of feature  creatinine_phosphokinase ************************** \n",
      "\n",
      "*****start of feature  diabetes *************************\n",
      "0    174\n",
      "1    125\n",
      "Name: diabetes, dtype: int64\n",
      "*****end of feature  diabetes ************************** \n",
      "\n",
      "*****start of feature  ejection_fraction *************************\n",
      "35    49\n",
      "38    40\n",
      "40    37\n",
      "25    36\n",
      "30    34\n",
      "60    31\n",
      "50    21\n",
      "45    20\n",
      "20    18\n",
      "55     3\n",
      "15     2\n",
      "62     2\n",
      "17     2\n",
      "65     1\n",
      "14     1\n",
      "80     1\n",
      "70     1\n",
      "Name: ejection_fraction, dtype: int64\n",
      "*****end of feature  ejection_fraction ************************** \n",
      "\n",
      "*****start of feature  high_blood_pressure *************************\n",
      "0    194\n",
      "1    105\n",
      "Name: high_blood_pressure, dtype: int64\n",
      "*****end of feature  high_blood_pressure ************************** \n",
      "\n",
      "*****start of feature  platelets *************************\n",
      "263358.03    25\n",
      "221000.00     4\n",
      "279000.00     4\n",
      "271000.00     4\n",
      "305000.00     4\n",
      "             ..\n",
      "227000.00     1\n",
      "289000.00     1\n",
      "300000.00     1\n",
      "217000.00     1\n",
      "742000.00     1\n",
      "Name: platelets, Length: 176, dtype: int64\n",
      "*****end of feature  platelets ************************** \n",
      "\n",
      "*****start of feature  serum_creatinine *************************\n",
      "1.00    50\n",
      "1.10    32\n",
      "0.90    32\n",
      "1.20    24\n",
      "0.80    24\n",
      "1.30    20\n",
      "0.70    19\n",
      "1.18    11\n",
      "1.40     9\n",
      "1.70     9\n",
      "1.83     8\n",
      "1.60     6\n",
      "1.90     5\n",
      "2.10     5\n",
      "1.50     5\n",
      "0.60     4\n",
      "1.80     4\n",
      "2.30     3\n",
      "2.70     3\n",
      "2.50     3\n",
      "3.50     2\n",
      "2.40     2\n",
      "3.00     2\n",
      "0.50     1\n",
      "5.00     1\n",
      "0.75     1\n",
      "6.10     1\n",
      "3.40     1\n",
      "3.70     1\n",
      "9.00     1\n",
      "4.00     1\n",
      "3.20     1\n",
      "5.80     1\n",
      "2.90     1\n",
      "2.00     1\n",
      "2.20     1\n",
      "6.80     1\n",
      "9.40     1\n",
      "4.40     1\n",
      "3.80     1\n",
      "Name: serum_creatinine, dtype: int64\n",
      "*****end of feature  serum_creatinine ************************** \n",
      "\n",
      "*****start of feature  serum_sodium *************************\n",
      "136    40\n",
      "137    38\n",
      "140    35\n",
      "134    32\n",
      "138    23\n",
      "139    22\n",
      "135    16\n",
      "132    14\n",
      "141    12\n",
      "142    11\n",
      "133    10\n",
      "145     9\n",
      "130     9\n",
      "144     5\n",
      "131     5\n",
      "127     3\n",
      "143     3\n",
      "128     2\n",
      "129     2\n",
      "121     1\n",
      "116     1\n",
      "146     1\n",
      "126     1\n",
      "124     1\n",
      "113     1\n",
      "125     1\n",
      "148     1\n",
      "Name: serum_sodium, dtype: int64\n",
      "*****end of feature  serum_sodium ************************** \n",
      "\n",
      "*****start of feature  sex *************************\n",
      "1    194\n",
      "0    105\n",
      "Name: sex, dtype: int64\n",
      "*****end of feature  sex ************************** \n",
      "\n",
      "*****start of feature  smoking *************************\n",
      "0    203\n",
      "1     96\n",
      "Name: smoking, dtype: int64\n",
      "*****end of feature  smoking ************************** \n",
      "\n",
      "*****start of feature  time *************************\n",
      "250    7\n",
      "187    7\n",
      "10     6\n",
      "186    6\n",
      "107    6\n",
      "      ..\n",
      "97     1\n",
      "96     1\n",
      "86     1\n",
      "77     1\n",
      "285    1\n",
      "Name: time, Length: 148, dtype: int64\n",
      "*****end of feature  time ************************** \n",
      "\n",
      "*****start of feature  DEATH_EVENT *************************\n",
      "0    203\n",
      "1     96\n",
      "Name: DEATH_EVENT, dtype: int64\n",
      "*****end of feature  DEATH_EVENT ************************** \n",
      "\n",
      "Feature of feat_sel_Num_to_Cat age: 5.430066\n",
      "Feature of feat_sel_Num_to_Cat creatinine_phosphokinase: 3.649016\n",
      "Feature of feat_sel_Num_to_Cat ejection_fraction: 18.060764\n",
      "Feature of feat_sel_Num_to_Cat platelets: 0.184443\n",
      "Feature of feat_sel_Num_to_Cat serum_creatinine: 25.004401\n",
      "Feature of feat_sel_Num_to_Cat serum_sodium: 5.237164\n",
      "Feature of feat_sel_Num_to_Cat time: 81.909871\n",
      "Feature of feat_sel_Cat_to_Cat chi2 anaemia: 0.721515\n",
      "Feature of feat_sel_Cat_to_Cat chi2 high_blood_pressure: 0.655560\n",
      "Feature of feat_sel_Cat_to_Cat chi2 diabetes: 0.069512\n",
      "Feature of feat_sel_Cat_to_Cat chi2 sex: 0.100904\n",
      "Feature of feat_sel_Cat_to_Cat chi2 smoking: 0.334204\n",
      "Feature of feat_sel_Cat_to_Cat mutual info age: 0.027132\n",
      "Feature of feat_sel_Cat_to_Cat mutual info anaemia: 0.031694\n",
      "Feature of feat_sel_Cat_to_Cat mutual info creatinine_phosphokinase: 0.025911\n",
      "Feature of feat_sel_Cat_to_Cat mutual info diabetes: 0.017438\n",
      "Feature of feat_sel_Cat_to_Cat mutual info ejection_fraction: 0.123432\n",
      "Feature of feat_sel_Cat_to_Cat mutual info high_blood_pressure: 0.006123\n",
      "Feature of feat_sel_Cat_to_Cat mutual info platelets: 0.004841\n",
      "Feature of feat_sel_Cat_to_Cat mutual info serum_creatinine: 0.127391\n",
      "Feature of feat_sel_Cat_to_Cat mutual info serum_sodium: 0.002648\n",
      "Feature of feat_sel_Cat_to_Cat mutual info sex: 0.000000\n",
      "Feature of feat_sel_Cat_to_Cat mutual info smoking: 0.000000\n",
      "Feature of feat_sel_Cat_to_Cat mutual info time: 0.258625\n",
      "Feature of feat_sel_Cat_to_Cat mutual info age: 0.041814\n",
      "Feature of feat_sel_Cat_to_Cat mutual info creatinine_phosphokinase: 0.029173\n",
      "Feature of feat_sel_Cat_to_Cat mutual info ejection_fraction: 0.078093\n",
      "Feature of feat_sel_Cat_to_Cat mutual info platelets: 0.004109\n",
      "Feature of feat_sel_Cat_to_Cat mutual info serum_creatinine: 0.049043\n",
      "Feature of feat_sel_Cat_to_Cat mutual info serum_sodium: 0.038074\n",
      "Feature of feat_sel_Cat_to_Cat mutual info time: 0.258246\n",
      "Feature of feat_sel_Cat_to_Cat mutual info anaemia: 0.019514\n",
      "Feature of feat_sel_Cat_to_Cat mutual info high_blood_pressure: 0.066157\n",
      "Feature of feat_sel_Cat_to_Cat mutual info diabetes: 0.028007\n",
      "Feature of feat_sel_Cat_to_Cat mutual info sex: 0.012432\n",
      "Feature of feat_sel_Cat_to_Cat mutual info smoking: 0.000000\n",
      "Optimum number of features: 9\n",
      "Score with 9 features: 0.873016\n",
      "Num Features: 9\n",
      "Selected Features: [ True  True False  True  True  True False  True  True  True  True False]\n",
      "Feature Ranking: [1 1 3 1 1 1 4 1 1 1 1 2]\n",
      "Num Features: 10\n",
      "Selected Features: [ True  True False  True  True  True False  True  True  True  True  True]\n",
      "Feature Ranking: [1 1 2 1 1 1 3 1 1 1 1 1]\n",
      "\n",
      ">>>>>>>>Calling init() from ageRounder\n",
      "\n",
      ">>>>>>>>Calling init() from Feature_Selector\n",
      "\n",
      ">>>>>>>>Calling init() from Feature_Selector\n",
      "\n",
      ">>>>>>>>Calling init() from Feature_Selector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator RFECV from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator ExtraTreeClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator ExtraTreesClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mariasiouzou\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SelectKBest from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[16:05:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:959: Check failed: header == serialisation_header_: \n\n  If you are loading a serialized model (like pickle in Python) generated by older\n  XGBoost, please export the model by calling `Booster.save_model` from that version\n  first, then load it back in current version.  There's a simple script for helping\n  the process. See:\n\n    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n\n  for reference to the script, and more details about differences between saving model and\n  serializing.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8572/3247217224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;31m#load model to save time of fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m \u001b[0mclf_v41\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mNDArrayWrapper\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mcompatibility\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mUnpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# For backward compatibility, we support NDArrayWrapper objects.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1715\u001b[0m         \u001b[0msetstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__setstate__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msetstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1717\u001b[1;33m             \u001b[0msetstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m         \u001b[0mslotstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__setstate__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m   1449\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m             \u001b[0mptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1451\u001b[1;33m             _check_call(\n\u001b[0m\u001b[0;32m   1452\u001b[0m                 _LIB.XGBoosterUnserializeFromBuffer(handle, ptr, length))\n\u001b[0;32m   1453\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'handle'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \"\"\"\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [16:05:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:959: Check failed: header == serialisation_header_: \n\n  If you are loading a serialized model (like pickle in Python) generated by older\n  XGBoost, please export the model by calling `Booster.save_model` from that version\n  first, then load it back in current version.  There's a simple script for helping\n  the process. See:\n\n    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n\n  for reference to the script, and more details about differences between saving model and\n  serializing.\n\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Aug 21 14:52:57 2020\n",
    "\n",
    "@author: k5000751\n",
    "\"\"\"\n",
    "\n",
    "## All necessary modules as well as different functions that will be used in this work are explicit here.\n",
    "#import all neccesary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle,gzip\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#import modules created \n",
    "import my_utils\n",
    "import missing_val_imput\n",
    "import feature_select\n",
    "import preprocessing\n",
    "import adhoc_transf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Classifier models to use\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "import joblib\n",
    "#Too see all columns when describe or head is called\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "#importing file into a pandas dataframe from UCI repository\n",
    "#https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records#\n",
    "path_data=r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\heart_failure_clinical_records_dataset.csv'\n",
    "\n",
    "df=pd.read_csv(path_data)\n",
    "\n",
    "df.head()\n",
    "#**********for a possible analysis for heart failure risk prediction\n",
    "#df2=df.loc[df['age']>60]\n",
    "#df2['age'].hist()\n",
    "#df2.info()\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df['DEATH_EVENT'].value_counts()\n",
    "#the data set is quite unbalanced 203 alive and 96 dead\n",
    "\n",
    "#Let's see the type of these features, apart from the proportion of non-null values\n",
    "my_utils.info_adhoc(df) #there is no missing values which is great\n",
    "\n",
    "#Let's see if there is any weird character in the dataset\n",
    "my_utils.df_values(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "##Step -1 Pipeline creation for data preparation\n",
    "#############################\n",
    "#Class for correcting misspelling of features and target columns\n",
    "#Due to a problem with the import with adhoc_transf\n",
    "class ageRounder(BaseEstimator, TransformerMixin):\n",
    "    def rounder (self,df):\n",
    "#     #Some fetures content seems to have the character \\t.\n",
    "#     #Let's remove such character for the sake of consistency\n",
    "         print('\\n>>>>>>>>Calling rounder')      \n",
    "         df['age']=np.around(df.loc[:,'age'])\n",
    "         return df\n",
    "     \n",
    "    def __init__(self):\n",
    "            print('\\n>>>>>>>>Calling init() from ageRounder')\n",
    "            \n",
    "    def fit(self, X, y=None):\n",
    "            print('\\n>>>>>>>>Calling fit() from ageRounder')\n",
    "            return self\n",
    "     \n",
    "    def transform(self,X,y=None):\n",
    "            print('\\n>>>>>>>>Calling transform() from ageRounder')        \n",
    "            df=self.rounder(X)       \n",
    "            return df\n",
    "     \n",
    "    def fit_transform(self, X, y=None,):\n",
    "            return self.fit(X, y).transform(X, y)\n",
    "    \n",
    "#############################\n",
    "##Step 0 Train-Test splitting\n",
    "#############################\n",
    "#Before starting to clean data, lets split train set and data set with stratrification on y=DEATH_EVENT\n",
    "\n",
    "train_set,test_set=train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"DEATH_EVENT\"])\n",
    "\n",
    "    \n",
    "train_set['DEATH_EVENT'].value_counts()\n",
    "test_set['DEATH_EVENT'].value_counts()\n",
    "    \n",
    "#lets back up the split just in case\n",
    "train_set_copy=train_set.copy()\n",
    "test_set_copy=test_set.copy()\n",
    "\n",
    "X_train=train_set_copy.drop('DEATH_EVENT',axis=1)\n",
    "y_train=train_set_copy['DEATH_EVENT'].copy()\n",
    "\n",
    "X_test=test_set_copy.drop('DEATH_EVENT',axis=1)\n",
    "y_test=test_set_copy['DEATH_EVENT'].copy()\n",
    "\n",
    "#Lets define numeric and category features\n",
    "numerical_features=['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']\n",
    "category_features= ['anaemia','high_blood_pressure','diabetes','sex', 'smoking']\n",
    "\n",
    "#############################\n",
    "##Step 1 Experimentation with feature selection\n",
    "#############################\n",
    "#1.1 Filter methods: anova for num feat, chi2 for cat feat, and mutual information for both\n",
    "#1.1.a ranking for numerical feaures with ANOVA\n",
    "feature_select.feat_sel_Num_to_Cat(X_train[numerical_features], y_train, 'all')\n",
    "#***output: time, ejection_fraction, serum_creatinine are the most relevant features\n",
    "# Feature of feat_sel_Num_to_Cat age: 5.437503\n",
    "# Feature of feat_sel_Num_to_Cat creatinine_phosphokinase: 3.649016\n",
    "# Feature of feat_sel_Num_to_Cat ejection_fraction: 18.060764\n",
    "# Feature of feat_sel_Num_to_Cat platelets: 0.184443\n",
    "# Feature of feat_sel_Num_to_Cat serum_creatinine: 25.004401\n",
    "# Feature of feat_sel_Num_to_Cat serum_sodium: 5.237164\n",
    "# Feature of feat_sel_Num_to_Cat time: 81.909871\n",
    "\n",
    "#1.1.b ranking for nominal feaures with chi2\n",
    "feature_select.feat_sel_Cat_to_Cat_chi2(X_train[category_features], y_train, 'all')\n",
    "#output:anaemia, high_blood_pressure, smoking are the most relevant features\n",
    "# Feature of feat_sel_Cat_to_Cat chi2 anaemia: 0.721515\n",
    "# Feature of feat_sel_Cat_to_Cat chi2 high_blood_pressure: 0.655560\n",
    "# Feature of feat_sel_Cat_to_Cat chi2 diabetes: 0.069512\n",
    "# Feature of feat_sel_Cat_to_Cat chi2 sex: 0.100904\n",
    "# Feature of feat_sel_Cat_to_Cat chi2 smoking: 0.334204\n",
    "\n",
    "#1.1.c selection for all feaures with mutual information\n",
    "feature_select.feat_sel_Cat_to_Cat_mutinf(X_train, y_train, 'all')\n",
    "#output:time, ejection_fraction, serum_creatinine  are the most relevant features\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info age: 0.041001\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info anaemia: 0.039651\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info creatinine_phosphokinase: 0.031781\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info diabetes: 0.000000\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info ejection_fraction: 0.050236\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info high_blood_pressure: 0.002306\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info platelets: 0.000000\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info serum_creatinine: 0.133361\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info serum_sodium: 0.000000\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info sex: 0.000000\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info smoking: 0.012959\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info time: 0.249232\n",
    "\n",
    "#1.1.d selection for numeric feaures with mutual information\n",
    "feature_select.feat_sel_Cat_to_Cat_mutinf(X_train[numerical_features], y_train, 'all')\n",
    "#output: time, ejection_fraction, serum_creatinine are the most relevant\n",
    "\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info age: 0.000944\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info creatinine_phosphokinase: 0.027680\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info ejection_fraction: 0.086096\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info platelets: 0.000000\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info serum_creatinine: 0.112365\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info serum_sodium: 0.014158\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info time: 0.259273\n",
    "#1.1.e selection for nominal feaures with mutual information\n",
    "feature_select.feat_sel_Cat_to_Cat_mutinf(X_train[category_features], y_train, 'all')\n",
    "#output: anaemia, diabetes\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info anaemia: 0.020536\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info high_blood_pressure: 0.000000\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info diabetes: 0.000000\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info sex: 0.000000\n",
    "# Feature of feat_sel_Cat_to_Cat mutual info smoking: 0.013656\n",
    "#1.2 Filter methods: RFE and RFECV for both\n",
    "#1.2.a RFE \n",
    "feature_select.feat_sel_RFE(X_train, y_train, k_out_features='all')\n",
    "#output\n",
    "# Optimum number of features: 9\n",
    "# Score with 9 features: 0.873016\n",
    "# Num Features: 9\n",
    "# Selected Features: Index(['age', 'anaemia', 'diabetes', 'ejection_fraction',\n",
    "#        'high_blood_pressure', 'serum_creatinine', 'serum_sodium','sex', 'smoking'],\n",
    "#       dtype='object')\n",
    "# Feature Ranking: [1 1 3 1 1 1 4 1 1 1 1 2]\n",
    "\n",
    "#1.2.b RFECV\n",
    "feature_select.feat_sel_RFECV(X_train, y_train)\n",
    "\n",
    "#output\n",
    "# Num Features: 10\n",
    "# Selected Features: Index(['age', 'anaemia', 'diabetes', 'ejection_fraction',\n",
    "#        'high_blood_pressure', 'serum_creatinine', 'serum_sodium', 'sex',\n",
    "#        'smoking', 'time'],\n",
    "#       dtype='object')\n",
    "\n",
    "# Feature Ranking: [1 1 2 1 1 1 3 1 1 1 1 1]\n",
    "\n",
    "    \n",
    "#############################\n",
    "##Step 2 Pipeline creation for data preparation\n",
    "#############################\n",
    "#we could perform two kinds of pipeline: a)a parallel pipeline that manages numerical and nominal features by separate,\n",
    "# b) a pipeline that first process the numeric features and then process a feature selection and classification the whole features\n",
    "\n",
    "#Looking at the values of the different features we can establish\n",
    "#1. There is no missing values in the entire dataset\n",
    "#2. All values are numeric type which implies that it can be processed correctly\n",
    "#3. In age feature there is a no int value 60,667 that should be cast down to 61\n",
    "\n",
    "\n",
    "###### Pipeline option a. parallel pipeline\n",
    "\n",
    "pipeline_numeric_feat= Pipeline([('round',ageRounder()),                                 \n",
    "                                 ('scaler', MinMaxScaler())\n",
    "                                 ])\n",
    "\n",
    "pipeline_numbranch=Pipeline([('num_feat',pipeline_numeric_feat),\n",
    "                             ('feat_sel_num',feature_select.Feature_Selector(strategy='wrapper_RFECV'))\n",
    "                            ])\n",
    "\n",
    "pipeline_num_featsel=Pipeline([('feat_sel_num',feature_select.Feature_Selector(strategy='wrapper_RFECV'))])\n",
    "# pipeline_category_feat= Pipeline(['features_select',feature_select.Feature_Selector(strategy='wrapper_RFECV')\n",
    "#                         ])\n",
    "\n",
    "dataprep_parallelpipe=ColumnTransformer([('numeric_pipe',pipeline_numbranch,numerical_features),\n",
    "                                 ('category_pipe',feature_select.Feature_Selector(strategy='wrapper_RFECV'), category_features)\n",
    "                                ])\n",
    "\n",
    "\n",
    "#############################\n",
    "##Step 3 Classifier initialization\n",
    "#############################\n",
    "#Several ensemble classifier with Cross validation will be applied\n",
    "#we take decision tree as base classifier\n",
    "\n",
    "#Init the clasfifier\n",
    "dectree_clf=DecisionTreeClassifier(random_state=42)\n",
    "rndforest_clf=RandomForestClassifier(random_state=42)\n",
    "extratree_clf=ExtraTreesClassifier(random_state=42)\n",
    "ada_clf= AdaBoostClassifier(random_state=42)\n",
    "gradboost_clf=GradientBoostingClassifier(random_state=42)\n",
    "xgboost_clf= xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "\n",
    "#############################\n",
    "##Step 4 Scoring initialization\n",
    "#############################\n",
    "\n",
    "#Lets define the scoring for the GridSearchCV\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'sensitivity': make_scorer(recall_score),\n",
    "    'specificity': make_scorer(recall_score,pos_label=0),\n",
    "    'precision':make_scorer(precision_score),\n",
    "    'f1':make_scorer(f1_score),\n",
    "    'roc_auc':make_scorer(roc_auc_score),\n",
    "    'mcc':make_scorer(matthews_corrcoef)    \n",
    "}\n",
    "\n",
    "#################################################\n",
    "####4.1 We will start with the parallel pipeline\n",
    "full_parallel_pipeline=Pipeline ([('data_prep',dataprep_parallelpipe),\n",
    "                                  ('clf',dectree_clf)])\n",
    "full_parallel_pipeline.get_params().keys()\n",
    "\n",
    "param_grid_fppipe={'clf': [dectree_clf,rndforest_clf,extratree_clf,ada_clf,gradboost_clf,xgboost_clf],\n",
    "               'data_prep__numeric_pipe__feat_sel_num__k_out_features':[2,3,4,5,6,7],\n",
    "               'data_prep__numeric_pipe__feat_sel_num__strategy':['filter_num','filter_mutinf','wrapper_RFE','wrapper_RFECV'],\n",
    "               'data_prep__category_pipe__k_out_features':['passthrough',1,2,3,4,5],\n",
    "               'data_prep__category_pipe__strategy':['filter_cat','filter_mutinf','wrapper_RFE','wrapper_RFECV']\n",
    "               }\n",
    "\n",
    "#load model to save time of fitting\n",
    "clf_v41=joblib.load(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41.pkl')\n",
    "\n",
    "\n",
    "\n",
    "clf_v41=GridSearchCV(full_parallel_pipeline,param_grid_fppipe,scoring=scoring,refit='accuracy', cv=5)\n",
    "clf_v41.fit(X_train,y_train)\n",
    "clf_v41.best_estimator_\n",
    "print('Params of best estimator of clf_v41:', clf_v41.best_params_)\n",
    "#This results obtained on 12.1.2021 are different from the original ones \n",
    "# Params of best estimator of clf_v41: \n",
    "#     {'clf': XGBClassifier(random_state=42), \n",
    "#      'data_prep__category_pipe__k_out_features': 1, \n",
    "#      'data_prep__category_pipe__strategy': 'filter_mutinf', \n",
    "#      'data_prep__numeric_pipe__feat_sel_num__k_out_features': 4, \n",
    "#      'data_prep__numeric_pipe__feat_sel_num__strategy': 'wrapper_RFECV'}\n",
    "\n",
    "print('Score of best estimator of clf_v41:', clf_v41.best_score_)\n",
    "#Score of best estimator of clf_v41: 0.8709639953542393\n",
    "\n",
    "print('Index of best estimator of clf_v41:', clf_v41.best_index_)\n",
    "#Index of best estimator of clf_v41: 2981\n",
    "\n",
    "df_results_clf_v41=pd.DataFrame(clf_v41.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_v41.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41_DMKD.xlsx',index=True)\n",
    "\n",
    "#Fit the best estimator with the test set\n",
    "clf_v41.refit\n",
    "preds = clf_v41.predict(X_test)\n",
    "np.mean(preds == y_test)#0.8333333333333334\n",
    "y_pred_41=clf_v41.predict(X_test)\n",
    "#Saving the model\n",
    "joblib.dump(clf_v41, r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41_DMKD.pkl', compress=1)\n",
    "\n",
    "\n",
    "#################################################\n",
    "####4.1 We will start with the parallel pipeline but only random forest and xgboost\n",
    "full_parallel_pipeline=Pipeline ([('data_prep',dataprep_parallelpipe),\n",
    "                                  ('clf',dectree_clf)\n",
    "                                ])\n",
    "full_parallel_pipeline.get_params().keys()\n",
    "\n",
    "param_grid_fppipe={'clf': [rndforest_clf,xgboost_clf],\n",
    "               'data_prep__numeric_pipe__feat_sel_num__k_out_features':[2,3,4,5,6,7],\n",
    "               'data_prep__numeric_pipe__feat_sel_num__strategy':['filter_num','filter_mutinf','wrapper_RFE','wrapper_RFECV'],\n",
    "               'data_prep__category_pipe__k_out_features':['passthrough',1,2,3,4,5],\n",
    "               'data_prep__category_pipe__strategy':['filter_cat','filter_mutinf','wrapper_RFE','wrapper_RFECV']\n",
    "               }\n",
    "\n",
    "#load model to save time of fitting\n",
    "clf_v411= joblib.load(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41.pkl')\n",
    "\n",
    "clf_v411=GridSearchCV(full_parallel_pipeline,param_grid_fppipe,scoring=scoring,refit='sensitivity', cv=5,n_jobs=-1)\n",
    "clf_v411.fit(X_train,y_train)\n",
    "clf_v411.best_estimator_\n",
    "print('Params of best estimator of clf_v41:', clf_v411.best_params_)\n",
    "#This results obtained on 12.1.2021 are different from the original ones \n",
    "# Params of best estimator of clf_v41: \n",
    "#     {'clf': XGBClassifier(random_state=42), \n",
    "#      'data_prep__category_pipe__k_out_features': 1, \n",
    "#      'data_prep__category_pipe__strategy': 'filter_mutinf', \n",
    "#      'data_prep__numeric_pipe__feat_sel_num__k_out_features': 4, \n",
    "#      'data_prep__numeric_pipe__feat_sel_num__strategy': 'wrapper_RFECV'}\n",
    "\n",
    "print('Score of best estimator of clf_v41:', clf_v411.best_score_)\n",
    "#Score of best estimator of clf_v41: 0.8709639953542393\n",
    "\n",
    "print('Index of best estimator of clf_v41:', clf_v41.best_index_)\n",
    "#Index of best estimator of clf_v41: 2981\n",
    "\n",
    "df_results_clf_v41=pd.DataFrame(clf_v41.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_v41.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41_informationfusion.xlsx',index=True)\n",
    "\n",
    "#Fit the best estimator with the test set\n",
    "clf_v41.refit\n",
    "preds = clf_v41.predict(X_test)\n",
    "np.mean(preds == y_test)#0.8333333333333334\n",
    "y_pred_41=clf_v41.predict(X_test)\n",
    "#Saving the model\n",
    "joblib.dump(clf_v41, r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41_informationfusion.pkl', compress=1)\n",
    "\n",
    "###################################\n",
    "###### Pipeline option b. \n",
    "#####Lets try with the sequential pipeline\n",
    "# dataprep_numericbranch=ColumnTransformer(['numeric_pipe',pipeline_numbranch,numerical_features])\n",
    "# dataprep_seq_pipe=Pipeline([('num_branch',dataprep_numericbranch),\n",
    "#                             ('feat_sel',feature_select.Feature_Selector(strategy='wrapper_RFECV'))\n",
    "#                             ])\n",
    "\n",
    "full_seq_pipeline=Pipeline([('feat_sel',feature_select.Feature_Selector(strategy='wrapper_RFECV')),\n",
    "                             ('clf',dectree_clf)\n",
    "                                ])\n",
    "\n",
    "full_seq_pipeline.get_params().keys()\n",
    "\n",
    "param_grid_fseqpipe={'clf': [dectree_clf,rndforest_clf,extratree_clf,ada_clf,gradboost_clf,xgboost_clf],\n",
    "               'feat_sel__k_out_features':[2,3,4,5,6,7,12],\n",
    "               'feat_sel__strategy':['filter_mutinf','wrapper_RFE','wrapper_RFECV']\n",
    "               }\n",
    "\n",
    "#load model to save time of fitting\n",
    "clf_v42= joblib.load(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v42.pkl')\n",
    "\n",
    "clf_v42=GridSearchCV(full_seq_pipeline,param_grid_fseqpipe,scoring=scoring,refit='accuracy', cv=5)\n",
    "X_train_seq=X_train.copy()\n",
    "X_train_seq[numerical_features]=pipeline_numeric_feat.fit_transform(X_train[numerical_features])\n",
    "clf_v42.fit(X_train_seq,y_train)\n",
    "clf_v42.best_estimator_\n",
    "print('Params of best estimator of clf_v42:', clf_v42.best_params_)\n",
    "#Results:Params of best estimator of clf_v42: Pipeline(steps=[('data_prep',\n",
    "# Pipeline(steps=[('feat_sel',\n",
    "#                  Feature_Selector(k_out_features=2, strategy='filter_mutinf')),\n",
    "#                 ('clf', XGBClassifier(random_state=42))])\n",
    "\n",
    "print('Score of best estimator of clf_v42:', clf_v42.best_score_)\n",
    "#Score of best estimator of clf_v42: 0.8709639953542393\n",
    "\n",
    "print('Index of best estimator of clf_v42:', clf_v42.best_index_)\n",
    "#Index of best estimator of clf_v42: 105\n",
    "\n",
    "df_results_clf_v42=pd.DataFrame(clf_v42.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_v42.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v42.xlsx',index=False)\n",
    "\n",
    "#Fit the best estimator with the test set\n",
    "clf_v42.refit\n",
    "X_test_seq=X_test.copy()\n",
    "X_test_seq[numerical_features]=pipeline_numeric_feat.fit_transform(X_test[numerical_features])\n",
    "\n",
    "preds = clf_v42.predict(X_test_seq)\n",
    "np.mean(preds == y_test)#0.7888888888888889\n",
    "y_pred_42=clf_v42.predict(X_test_seq)\n",
    "#Saving the model\n",
    "#Ojo hemos sobreescrito el archivo pkl por error hay que volver a hacer el grid search\n",
    "joblib.dump(clf_v42, r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v42.pkl', compress=1)\n",
    "\n",
    "############################################\n",
    "####4.1_bis we repeat the 4.1 without xboost\n",
    "full_parallel_pipeline=Pipeline ([('data_prep',dataprep_parallelpipe),\n",
    "                                  ('clf',dectree_clf)])\n",
    "full_parallel_pipeline.get_params().keys()\n",
    "\n",
    "param_grid_fppipe_bis={'clf': [dectree_clf,rndforest_clf,extratree_clf,ada_clf,gradboost_clf],\n",
    "               'data_prep__numeric_pipe__feat_sel_num__k_out_features':[2,3,4,5,6,7],\n",
    "               'data_prep__numeric_pipe__feat_sel_num__strategy':['filter_num','filter_mutinf','wrapper_RFE','wrapper_RFECV'],\n",
    "               'data_prep__category_pipe__k_out_features':['passthrough',1,2,3,4,5],\n",
    "               'data_prep__category_pipe__strategy':['filter_cat','filter_mutinf','wrapper_RFE','wrapper_RFECV']\n",
    "               }\n",
    "\n",
    "clf_v41_bis=GridSearchCV(full_parallel_pipeline,param_grid_fppipe_bis,scoring=scoring,refit='accuracy', cv=5)\n",
    "clf_v41_bis.fit(X_train,y_train)\n",
    "clf_v41_bis.best_estimator_\n",
    "print('Params of best estimator of clf_v41_bis:', clf_v41_bis.best_params_)\n",
    "# #Results:Params of best estimator of clf_v41_bis: {'clf': ExtraTreesClassifier(random_state=42),\n",
    " # 'data_prep__category_pipe__k_out_features': 4,\n",
    " # 'data_prep__category_pipe__strategy': 'filter_cat',\n",
    " # 'data_prep__numeric_pipe__feat_sel_num__k_out_features': 5,\n",
    " # 'data_prep__numeric_pipe__feat_sel_num__strategy': 'filter_mutinf'}\n",
    "\n",
    "print('Score of best estimator of clf_v41_bis:', clf_v41_bis.best_score_)\n",
    "#Score of best estimator of clf_v41_bis: 0.8662020905923346\n",
    "\n",
    "print('Index of best estimator of clf_v41_bis:', clf_v41_bis.best_index_)\n",
    "#Index of best estimator of clf_v41: 1549\n",
    "\n",
    "df_results_clf_v41_bis=pd.DataFrame(clf_v41_bis.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_v41_bis.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41_bis.xlsx',index=False)\n",
    "\n",
    "#Fit the best estimator with the test set\n",
    "clf_v41_bis.refit\n",
    "preds = clf_v41_bis.predict(X_test)\n",
    "np.mean(preds == y_test)#0.7777777777777778\n",
    "y_pred_41_bis=clf_v41_bis.predict(X_test)\n",
    "#Saving the model\n",
    "joblib.dump(clf_v41_bis, r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41_bis.pkl', compress=1)\n",
    "\n",
    "\n",
    "############################################\n",
    "####4.3 pipeline without feature selection\n",
    "dataprep_numericbranch=ColumnTransformer(['numeric_pipe',pipeline_numeric_feat,numerical_features])\n",
    "\n",
    "X_train_nofeat=X_train.copy()\n",
    "X_train_nofeat[numerical_features]=pipeline_numeric_feat.fit_transform(X_train[numerical_features])\n",
    "\n",
    "full_nofeatsel_pipeline=Pipeline([('clf',dectree_clf)])\n",
    "\n",
    "full_nofeatsel_pipeline.get_params().keys()\n",
    "\n",
    "param_grid_nofeatselpipe={'clf': [dectree_clf,rndforest_clf,extratree_clf,ada_clf,gradboost_clf,xgboost_clf]\n",
    "               }\n",
    "\n",
    "#load model to save time of fitting\n",
    "clf_v43= joblib.load(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v43.pkl')\n",
    "\n",
    "clf_v43=GridSearchCV(full_nofeatsel_pipeline,param_grid_nofeatselpipe,scoring=scoring,refit='accuracy', cv=5)\n",
    "clf_v43.fit(X_train_nofeat,y_train)\n",
    "clf_v43.best_estimator_\n",
    "print('Params of best estimator of clf_v43:', clf_v43.best_params_)\n",
    "#Results:Params of best estimator of clf_v43: Pipeline(steps=[('data_prep',\n",
    "# Pipeline(steps=[{'clf': RandomForestClassifier(random_state=42)}])\n",
    "\n",
    "print('Score of best estimator of clf_v43:', clf_v43.best_score_)\n",
    "#Score of best estimator of clf_v43: 0.8518002322880373\n",
    "\n",
    "print('Index of best estimator of clf_v43:', clf_v43.best_index_)\n",
    "#Index of best estimator of clf_v43: 105\n",
    "\n",
    "df_results_clf_v43=pd.DataFrame(clf_v43.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_v43.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v43.xlsx',index=False)\n",
    "\n",
    "#Fit the best estimator with the test set\n",
    "clf_v43.refit\n",
    "X_test_nofeat=X_test.copy()\n",
    "X_test_nofeat[numerical_features]=pipeline_numeric_feat.fit_transform(X_test[numerical_features])\n",
    "\n",
    "preds = clf_v43.predict(X_test_nofeat)\n",
    "np.mean(preds == y_test)#0.7444444444444445\n",
    "y_pred_43=clf_v43.predict(X_test_nofeat)\n",
    "#Saving the model\n",
    "#Ojo hemos sobreescrito el archivo pkl por error hay que volver a hacer el grid search\n",
    "joblib.dump(clf_v43, r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v43.pkl', compress=1)\n",
    "\n",
    "######################################################\n",
    "#Mergin the results with the test set into one place\n",
    "# overall_test_results={'clf':['clf_v41','clf_v42'],\n",
    "#                  'params':[clf_v41.best_params_,clf_v42.best_params_],\n",
    "#                  'accuracy_test':[accuracy_score(y_test, y_pred_41),accuracy_score(y_test, y_pred_42)],\n",
    "#                  'f1_test':[f1_score(y_test, y_pred_41, average='weighted'), f1_score(y_test, y_pred_42, average='weighted')],\n",
    "#                  'precision_test':[precision_score(y_test, y_pred_41, average='weighted'),precision_score(y_test, y_pred_42, average='weighted')],\n",
    "#                  'recall_test':[recall_score(y_test, y_pred_41, average='weighted'), recall_score(y_test, y_pred_42, average='weighted')],\n",
    "#                  'specificity_test':[recall_score(y_test, y_pred_41, pos_label=0),recall_score(y_test, y_pred_42, pos_label=0)],\n",
    "#                  'roc_auc_test':[roc_auc_score(y_test, y_pred_41),roc_auc_score(y_test, y_pred_42)],\n",
    "#                  'mcc_test':[matthews_corrcoef(y_test, y_pred_41), matthews_corrcoef(y_test, y_pred_42)]\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "overall_test_results_clfv43={'clf':['clf_v43'],\n",
    "                 'params':[clf_v43.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_43)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_43, average='weighted')],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_43, average='weighted')],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_43, average='weighted')],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_43, pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_43)],\n",
    "                 'mcc_test':[matthews_corrcoef(y_test, y_pred_43)]\n",
    "    }\n",
    "\n",
    "df_overall_test_results_paper=pd.DataFrame(data=overall_test_results_clfv43)\n",
    "df_overall_test_results_paper.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\df_overall_test_results_paper_clf43.xlsx',index=False)\n",
    "\n",
    "#########################\n",
    "#The winner model is clf_v41.best_estimator with the following params\n",
    "#{'clf': XGBClassifier(random_state=42),\n",
    "# 'data_prep__category_pipe__k_out_features': 1,\n",
    "# 'data_prep__category_pipe__strategy': 'filter_cat',\n",
    "# 'data_prep__numeric_pipe__feat_sel_num__k_out_features': 3,\n",
    "# 'data_prep__numeric_pipe__feat_sel_num__strategy': 'filter_mutinf'}\n",
    "win_model=clf_v41.best_estimator_\n",
    "\n",
    "#The features selected in the win_model were:\n",
    "#anaemia, time, ejection_fraction, serum_creatinine \n",
    "\n",
    "X_train_feat=X_train[['anaemia','ejection_fraction','serum_creatinine','time']].copy()\n",
    "X_test_feat=X_test[['anaemia','ejection_fraction','serum_creatinine','time']].copy()\n",
    "\n",
    "#A Decision tree with the max_depth of XGBoost (equals to 3) and the feature selection results will be made\n",
    "#to show it graphically\n",
    "num_feat_sel=['ejection_fraction','serum_creatinine','time']\n",
    "minmaxtrain=MinMaxScaler()\n",
    "minmaxtest=MinMaxScaler()\n",
    "\n",
    "X_train_feat[num_feat_sel]=minmaxtrain.fit_transform(X_train_feat[num_feat_sel])\n",
    "X_test_feat[num_feat_sel]=minmaxtest.fit_transform(X_test_feat[num_feat_sel])\n",
    "\n",
    "X_train_feat.head()\n",
    "\n",
    "#####################\n",
    "#Building the DT\n",
    "clf_tree_feat=DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "#use grid_search_CV to see the results\n",
    "clf_tree_feat.get_params().keys()\n",
    "\n",
    "param_grid_clf_tree_feat={'max_depth': [3,None]}\n",
    "\n",
    "clf_tree_feat_grid=GridSearchCV(clf_tree_feat,param_grid_clf_tree_feat,scoring=scoring,refit='accuracy', cv=5)\n",
    "clf_tree_feat_grid.fit(X_train_feat,y_train)\n",
    "clf_tree_feat_grid.best_estimator_\n",
    "df_results_clf_tree_feat=pd.DataFrame(clf_tree_feat_grid.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_tree_feat.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_tree_feat.xlsx',index=False)\n",
    "#Fit the best estimator with the test set\n",
    "clf_tree_feat_grid.refit\n",
    "\n",
    "preds = clf_tree_feat_grid.predict(X_test_feat)\n",
    "np.mean(preds == y_test)#0.7444444444444445\n",
    "y_pred_tree=clf_tree_feat_grid.predict(X_test_feat)\n",
    "\n",
    "overall_test_results_clf_tree_feat={'clf':['clf_tree_feat'],\n",
    "                 'params':[clf_tree_feat_grid.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_tree)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_tree, average='weighted')],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_tree, average='weighted')],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_tree, average='weighted')],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_tree, pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_tree)],\n",
    "                 'mcc_test':[matthews_corrcoef(y_test, y_pred_tree)]\n",
    "    }\n",
    "#Saving results with test set to calculate interpretability measures\n",
    "df_overall_test_results_clf_tree_feat=pd.DataFrame(data=overall_test_results_clf_tree_feat)\n",
    "df_overall_test_results_clf_tree_feat.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\overall_test_results_clf_tree_feat.xlsx',index=False)\n",
    "\n",
    "##############################\n",
    "#Lets print the decision tree\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf_tree_feat_grid.best_estimator_, \n",
    "                  feature_names=X_train_feat.columns,  \n",
    "                  class_names=y_train.values.astype('str'),  \n",
    "                  filled=True, rounded=True,  \n",
    "                  special_characters=True,\n",
    "                   out_file=None,\n",
    "                           )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = \"png\"\n",
    "graph.render(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\dt_featsel_graph')\n",
    "\n",
    "#the decisiontree shows cut point in the branches with the following values\n",
    "#time=0.254, 0.175\n",
    "#ejection_fraction=0.115, 0.192\n",
    "#serum creatinine=0.107\n",
    "#To improve readability of the graph lets transform these values to their original ones\n",
    "#Inverting time\n",
    "X_train_feat_time=X_train[['time']].copy()\n",
    "minmaxtrain_time=MinMaxScaler()\n",
    "X_train_feat_time=minmaxtrain_time.fit_transform(X_train_feat_time)\n",
    "time_1=minmaxtrain_time.inverse_transform(np.array(0.254).reshape(1,-1))\n",
    "time_2=minmaxtrain_time.inverse_transform(np.array(0.175).reshape(1,-1))\n",
    "#Inverting ejection_fraction\n",
    "X_train_feat_ef=X_train[['ejection_fraction']].copy()\n",
    "minmaxtrain_ef=MinMaxScaler()\n",
    "X_train_feat_ef=minmaxtrain_ef.fit_transform(X_train_feat_ef)\n",
    "ef_1=minmaxtrain_ef.inverse_transform(np.array(0.115).reshape(1,-1))\n",
    "ef_2=minmaxtrain_ef.inverse_transform(np.array(0.192).reshape(1,-1))\n",
    "#Inverting serum_creatinine\n",
    "X_train_feat_sc=X_train[['serum_creatinine']].copy()\n",
    "minmaxtrain_sc=MinMaxScaler()\n",
    "X_train_feat_sc=minmaxtrain_sc.fit_transform(X_train_feat_sc)\n",
    "sc_1=minmaxtrain_sc.inverse_transform(np.array(0.107).reshape(1,-1))\n",
    "print ('time_1: ',time_1,'; time_2: ',time_2,'; ef_1: ',ef_1,'; ef_2: ',ef_2,'; sc_1: ',sc_1)\n",
    "\n",
    "############\n",
    "#Update, the best estimator is not performed by removing the minmax scaler so the following part is deprecated.\n",
    "#The plot and decision rules shown are affected by the minmax_scaler\n",
    "#we perform the same without the scaling and check the classification metrics\n",
    "X_train_feat=X_train[['anaemia','ejection_fraction','serum_creatinine','time']].copy()\n",
    "X_test_feat=X_test[['anaemia','ejection_fraction','serum_creatinine','time']].copy()\n",
    "\n",
    "#Building the DT\n",
    "clf_tree_feat_nomin=DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "#use grid_search_CV to see the results\n",
    "clf_tree_feat.get_params().keys()\n",
    "\n",
    "param_grid_clf_tree_feat_nomin={'max_depth': [3,None]}\n",
    "\n",
    "clf_tree_feat_grid_nomin=GridSearchCV(clf_tree_feat_nomin,param_grid_clf_tree_feat_nomin,scoring=scoring,refit='accuracy', cv=5,n_jobs=-1)\n",
    "clf_tree_feat_grid_nomin.fit(X_train_feat,y_train)\n",
    "clf_tree_feat_grid_nomin.best_estimator_\n",
    "df_results_clf_tree_feat_nomin=pd.DataFrame(clf_tree_feat_grid_nomin.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_tree_feat_nomin.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_tree_feat_nomin.xlsx',index=False)\n",
    "#Fit the best estimator with the test set\n",
    "clf_tree_feat_grid_nomin.refit\n",
    "\n",
    "preds = clf_tree_feat_grid_nomin.predict(X_test_feat)\n",
    "np.mean(preds == y_test)#0.7444444444444445\n",
    "y_pred_tree_nomin=clf_tree_feat_grid_nomin.predict(X_test_feat)\n",
    "\n",
    "overall_test_results_clf_tree_feat_nomin={'clf':['clf_tree_feat_nomin'],\n",
    "                 'params':[clf_tree_feat_grid_nomin.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_tree_nomin)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_tree_nomin, average='weighted')],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_tree_nomin, average='weighted')],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_tree_nomin, average='weighted')],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_tree_nomin, pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_tree_nomin)],\n",
    "                 'mcc_test':[matthews_corrcoef(y_test, y_pred_tree)]\n",
    "    }\n",
    "#Saving results with test set to calculate interpretability measures\n",
    "df_overall_test_results_clf_tree_feat_nomin=pd.DataFrame(data=overall_test_results_clf_tree_feat_nomin)\n",
    "df_overall_test_results_clf_tree_feat_nomin.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\overall_test_results_clf_tree_feat_nomin.xlsx',index=False)\n",
    "\n",
    "\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf_tree_feat_grid_nomin.best_estimator_, \n",
    "                  feature_names=X_train_feat.columns,  \n",
    "                  class_names=y_train.values.astype('str'),  \n",
    "                  filled=True, rounded=True,  \n",
    "                  special_characters=True,\n",
    "                   out_file=None,\n",
    "                           )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = \"png\"\n",
    "graph.render(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\dt_featsel_nomin_graph')\n",
    "\n",
    "\n",
    "#########################\n",
    "#5. Repeat the process without scaling features as the results seem to improve\n",
    "\n",
    "\n",
    "dataprep_parallelpipe_nosc=ColumnTransformer([('numeric_pipe',feature_select.Feature_Selector(strategy='wrapper_RFECV'), numerical_features),\n",
    "                                 ('category_pipe',feature_select.Feature_Selector(strategy='wrapper_RFECV'), category_features)\n",
    "                                ])\n",
    "\n",
    "full_parallel_pipel_nosc=Pipeline ([('data_prep',dataprep_parallelpipe_nosc),\n",
    "                                  ('clf',dectree_clf)\n",
    "                                ])\n",
    "full_parallel_pipel_nosc.get_params().keys()\n",
    "\n",
    "param_grid_fppipe_nosc={'clf': [dectree_clf,rndforest_clf,extratree_clf,ada_clf,gradboost_clf,xgboost_clf],\n",
    "               'data_prep__numeric_pipe__k_out_features':[2,3,4,5,6,7],\n",
    "               'data_prep__numeric_pipe__strategy':['filter_num','filter_mutinf','wrapper_RFE','wrapper_RFECV'],\n",
    "               'data_prep__category_pipe__k_out_features':['passthrough',1,2,3,4,5],\n",
    "               'data_prep__category_pipe__strategy':['filter_cat','filter_mutinf','wrapper_RFE','wrapper_RFECV']\n",
    "               }\n",
    "\n",
    "#load model to save time of fitting\n",
    "clf_v51= joblib.load(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v41.pkl')\n",
    "\n",
    "clf_v51=GridSearchCV(full_parallel_pipel_nosc,param_grid_fppipe_nosc,scoring=scoring,refit='accuracy', cv=5)\n",
    "clf_v51.fit(X_train,y_train)\n",
    "clf_v51.best_estimator_\n",
    "print('Params of best estimator of clf_v51:', clf_v51.best_params_)\n",
    "# #Results:Params of best estimator of clf_v51: Pipeline(steps=[('data_prep',\n",
    "#                  'data_prep',\n",
    "# clf_v51.best_params_)\n",
    "# Params of best estimator of clf_v51:\n",
    "#     {'clf': ExtraTreesClassifier(random_state=42), \n",
    "#      'data_prep__category_pipe__k_out_features': 1, \n",
    "#      'data_prep__category_pipe__strategy': 'filter_mutinf',\n",
    "#      'data_prep__numeric_pipe__k_out_features': 5, \n",
    "#      'data_prep__numeric_pipe__strategy': 'filter_num'}\n",
    "\n",
    "print('Score of best estimator of clf_v51:', clf_v51.best_score_)\n",
    "#Score of best estimator of clf_v51: 0.8709639953542393\n",
    "\n",
    "print('Index of best estimator of clf_v51:', clf_v51.best_index_)\n",
    "#Index of best estimator of clf_v51: 1284\n",
    "\n",
    "df_results_clf_v51=pd.DataFrame(clf_v51.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_v51.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v51.xlsx',index=True)\n",
    "\n",
    "#Fit the best estimator with the test set\n",
    "clf_v51.refit\n",
    "preds = clf_v51.predict(X_test)\n",
    "np.mean(preds == y_test)#0.8333333333333334\n",
    "y_pred_51=clf_v51.predict(X_test)\n",
    "#Saving the model\n",
    "joblib.dump(clf_v51, r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v51.pkl', compress=1)\n",
    "\n",
    "###################################\n",
    "###### Pipeline option b. \n",
    "#####Lets try with the sequential pipeline\n",
    "# dataprep_numericbranch=ColumnTransformer(['numeric_pipe',pipeline_numbranch,numerical_features])\n",
    "# dataprep_seq_pipe=Pipeline([('num_branch',dataprep_numericbranch),\n",
    "#                             ('feat_sel',feature_select.Feature_Selector(strategy='wrapper_RFECV'))\n",
    "#                             ])\n",
    "\n",
    "full_seq_pipeline=Pipeline([('feat_sel',feature_select.Feature_Selector(strategy='wrapper_RFECV')),\n",
    "                             ('clf',dectree_clf)\n",
    "                                ])\n",
    "\n",
    "full_seq_pipeline.get_params().keys()\n",
    "\n",
    "param_grid_fseqpipe={'clf': [dectree_clf,rndforest_clf,extratree_clf,ada_clf,gradboost_clf,xgboost_clf],\n",
    "               'feat_sel__k_out_features':[2,3,4,5,6,7,12],\n",
    "               'feat_sel__strategy':['filter_mutinf','wrapper_RFE','wrapper_RFECV']\n",
    "               }\n",
    "\n",
    "#load model to save time of fitting\n",
    "clf_v52= joblib.load(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v52.pkl')\n",
    "\n",
    "clf_v52=GridSearchCV(full_seq_pipeline,param_grid_fseqpipe,scoring=scoring,refit='accuracy', cv=5)\n",
    "X_train_seq=X_train.copy()\n",
    "#X_train_seq[numerical_features]=pipeline_numeric_feat.fit_transform(X_train[numerical_features])\n",
    "clf_v52.fit(X_train_seq,y_train)\n",
    "clf_v52.best_estimator_\n",
    "print('Params of best estimator of clf_v52:', clf_v52.best_params_)\n",
    "#Results:Params of best estimator of clf_v52: Pipeline(steps=[('data_prep',\n",
    "# Pipeline(steps=[('feat_sel',\n",
    "#                  Feature_Selector(k_out_features=2, strategy='filter_mutinf')),\n",
    "#                 ('clf', XGBClassifier(random_state=42))])\n",
    "\n",
    "print('Score of best estimator of clf_v52:', clf_v52.best_score_)\n",
    "#Score of best estimator of clf_v52: 0.856562137049942\n",
    "\n",
    "print('Index of best estimator of clf_v52:', clf_v52.best_index_)\n",
    "#Index of best estimator of clf_v42: 105\n",
    "\n",
    "df_results_clf_v52=pd.DataFrame(clf_v52.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_v52.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v52.xlsx',index=False)\n",
    "\n",
    "#Fit the best estimator with the test set\n",
    "clf_v52.refit\n",
    "X_test_seq=X_test.copy()\n",
    "#X_test_seq[numerical_features]=pipeline_numeric_feat.fit_transform(X_test[numerical_features])\n",
    "\n",
    "preds = clf_v52.predict(X_test_seq)\n",
    "np.mean(preds == y_test)#0.8222222222222222\n",
    "y_pred_52=clf_v52.predict(X_test_seq)\n",
    "#Saving the model\n",
    "joblib.dump(clf_v52, r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v52.pkl', compress=1)\n",
    "############################################\n",
    "####4.3 pipeline without feature selection\n",
    "X_train_nofeatsc=X_train.copy()\n",
    "\n",
    "full_nofeatselsc_pipeline=Pipeline([('clf',dectree_clf)])\n",
    "\n",
    "full_nofeatselsc_pipeline.get_params().keys()\n",
    "\n",
    "param_grid_nofeatscselpipe={'clf': [dectree_clf,rndforest_clf,extratree_clf,ada_clf,gradboost_clf,xgboost_clf]\n",
    "               }\n",
    "\n",
    "#load model to save time of fitting\n",
    "clf_v53= joblib.load(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v53.pkl')\n",
    "\n",
    "clf_v53=GridSearchCV(full_nofeatselsc_pipeline,param_grid_nofeatscselpipe,scoring=scoring,refit='accuracy', cv=5)\n",
    "clf_v53.fit(X_train_nofeatsc,y_train)\n",
    "clf_v53.best_estimator_\n",
    "print('Params of best estimator of clf_v53:', clf_v53.best_params_)\n",
    "#Results:Params of best estimator of clf_v53: Pipeline(steps=[('data_prep',\n",
    "# Pipeline(steps=[{'clf': RandomForestClassifier(random_state=42)}])\n",
    "\n",
    "print('Score of best estimator of clf_v53:', clf_v53.best_score_)\n",
    "#Score of best estimator of clf_v53: 0.856562137049942\n",
    "\n",
    "print('Index of best estimator of clf_v43:', clf_v53.best_index_)\n",
    "#Index of best estimator of clf_v43: 105\n",
    "\n",
    "df_results_clf_v53=pd.DataFrame(clf_v53.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_v53.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v53.xlsx',index=False)\n",
    "\n",
    "#Fit the best estimator with the test set\n",
    "clf_v53.refit\n",
    "X_test_nofeat=X_test.copy()\n",
    "#X_test_nofeat[numerical_features]=pipeline_numeric_feat.fit_transform(X_test[numerical_features])\n",
    "\n",
    "preds = clf_v53.predict(X_test_nofeat)\n",
    "np.mean(preds == y_test)#0.8111111111111111\n",
    "y_pred_53=clf_v53.predict(X_test_nofeat)\n",
    "#Saving the model\n",
    "\n",
    "joblib.dump(clf_v53, r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_v53.pkl', compress=1)\n",
    "\n",
    "######################################################\n",
    "#Mergin the results with the test set into one place\n",
    "overall_test_results={'clf':['clf_v51','clf_v52','clf_v53'],\n",
    "                  'params':[clf_v51.best_params_,clf_v52.best_params_,clf_v53.best_params_],\n",
    "                  'accuracy_test':[accuracy_score(y_test, y_pred_51),accuracy_score(y_test, y_pred_52),accuracy_score(y_test, y_pred_53)],\n",
    "                  'f1_test':[f1_score(y_test, y_pred_51, average='weighted'), f1_score(y_test, y_pred_52, average='weighted'), f1_score(y_test, y_pred_53, average='weighted')],\n",
    "                  'precision_test':[precision_score(y_test, y_pred_51, average='weighted'),precision_score(y_test, y_pred_52, average='weighted'),precision_score(y_test, y_pred_53, average='weighted')],\n",
    "                  'recall_test':[recall_score(y_test, y_pred_51, average='weighted'), recall_score(y_test, y_pred_52, average='weighted'), recall_score(y_test, y_pred_53, average='weighted')],\n",
    "                  'specificity_test':[recall_score(y_test, y_pred_51, pos_label=0),recall_score(y_test, y_pred_52, pos_label=0),recall_score(y_test, y_pred_53, pos_label=0)],\n",
    "                  'roc_auc_test':[roc_auc_score(y_test, y_pred_51),roc_auc_score(y_test, y_pred_52),roc_auc_score(y_test, y_pred_53)],\n",
    "                  'mcc_test':[matthews_corrcoef(y_test, y_pred_51), matthews_corrcoef(y_test, y_pred_52), matthews_corrcoef(y_test, y_pred_53)]\n",
    "     }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_overall_test_results_paper=pd.DataFrame(data=overall_test_results)\n",
    "df_overall_test_results_paper.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\df_overall_test_results_paper_clf5x.xlsx',index=False)\n",
    "\n",
    "#########################\n",
    "#The winner model is clf_v41.best_estimator with the following params\n",
    "#{'clf': XGBClassifier(random_state=42),\n",
    "# 'data_prep__category_pipe__k_out_features': 1,\n",
    "# 'data_prep__category_pipe__strategy': 'filter_cat',\n",
    "# 'data_prep__numeric_pipe__feat_sel_num__k_out_features': 3,\n",
    "# 'data_prep__numeric_pipe__feat_sel_num__strategy': 'filter_mutinf'}\n",
    "win_model=clf_v41.best_estimator_\n",
    "\n",
    "#The features selected in the win_model were:\n",
    "#anaemia, time, ejection_fraction, serum_creatinine \n",
    "\n",
    "X_train_feat=X_train[['anaemia','ejection_fraction','serum_creatinine','time']].copy()\n",
    "X_test_feat=X_test[['anaemia','ejection_fraction','serum_creatinine','time']].copy()\n",
    "\n",
    "#A Decision tree with the max_depth of XGBoost (equals to 3) and the feature selection results will be made\n",
    "#to show it graphically\n",
    "num_feat_sel=['ejection_fraction','serum_creatinine','time']\n",
    "\n",
    "X_train_feat[num_feat_sel]=MinMaxScaler().fit_transform(X_train_feat[num_feat_sel])\n",
    "X_test_feat[num_feat_sel]=MinMaxScaler().fit_transform(X_test_feat[num_feat_sel])\n",
    "\n",
    "X_train_feat.head()\n",
    "\n",
    "#Building the DT\n",
    "clf_tree_feat=DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "#use grid_search_CV to see the results\n",
    "clf_tree_feat.get_params().keys()\n",
    "\n",
    "param_grid_clf_tree_feat={'max_depth': [3,None]}\n",
    "\n",
    "clf_tree_feat_grid=GridSearchCV(clf_tree_feat,param_grid_clf_tree_feat,scoring=scoring,refit='accuracy', cv=5)\n",
    "clf_tree_feat_grid.fit(X_train_feat,y_train)\n",
    "clf_tree_feat_grid.best_estimator_\n",
    "df_results_clf_tree_feat=pd.DataFrame(clf_tree_feat_grid.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_tree_feat.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_tree_feat.xlsx',index=False)\n",
    "#Fit the best estimator with the test set\n",
    "clf_tree_feat_grid.refit\n",
    "\n",
    "preds = clf_tree_feat_grid.predict(X_test_feat)\n",
    "np.mean(preds == y_test)#0.7444444444444445\n",
    "y_pred_tree=clf_tree_feat_grid.predict(X_test_feat)\n",
    "\n",
    "overall_test_results_clf_tree_feat={'clf':['clf_tree_feat'],\n",
    "                 'params':[clf_tree_feat_grid.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_tree)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_tree, average='weighted')],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_tree, average='weighted')],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_tree, average='weighted')],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_tree, pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_tree)],\n",
    "                 'mcc_test':[matthews_corrcoef(y_test, y_pred_tree)]\n",
    "    }\n",
    "#Saving results with test set to calculate interpretability measures\n",
    "df_overall_test_results_clf_tree_feat=pd.DataFrame(data=overall_test_results_clf_tree_feat)\n",
    "df_overall_test_results_clf_tree_feat.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\overall_test_results_clf_tree_feat.xlsx',index=False)\n",
    "\n",
    "#Lets print the decision tree\n",
    "from sklearn import tree\n",
    "fig = plt.figure(figsize=(100,100))\n",
    "_ = tree.plot_tree(clf_tree_feat_grid.best_estimator_, \n",
    "                   feature_names=X_train_feat.columns,  \n",
    "                   class_names=y_train.values.astype('str'),\n",
    "                   filled=True)\n",
    "\n",
    "\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf_tree_feat_grid.best_estimator_, \n",
    "                  feature_names=X_train_feat.columns,  \n",
    "                  class_names=y_train.values.astype('str'),  \n",
    "                  filled=True, rounded=True,  \n",
    "                  special_characters=True,\n",
    "                   out_file=None,\n",
    "                           )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = \"png\"\n",
    "graph.render(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\dt_featsel_graph')\n",
    "\n",
    "#The plot and decision rules shown are affected by the minmax_scaler\n",
    "#we perform the same without the scaling and check the classification metrics\n",
    "X_train_feat=X_train[['anaemia','ejection_fraction','serum_creatinine','time']].copy()\n",
    "X_test_feat=X_test[['anaemia','ejection_fraction','serum_creatinine','time']].copy()\n",
    "\n",
    "#Building the DT\n",
    "clf_tree_feat_nomin=DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "#use grid_search_CV to see the results\n",
    "clf_tree_feat.get_params().keys()\n",
    "\n",
    "param_grid_clf_tree_feat_nomin={'max_depth': [3,None]}\n",
    "\n",
    "clf_tree_feat_grid_nomin=GridSearchCV(clf_tree_feat_nomin,param_grid_clf_tree_feat_nomin,scoring=scoring,refit='accuracy', cv=5,n_jobs=-1)\n",
    "clf_tree_feat_grid_nomin.fit(X_train_feat,y_train)\n",
    "clf_tree_feat_grid_nomin.best_estimator_\n",
    "df_results_clf_tree_feat_nomin=pd.DataFrame(clf_tree_feat_grid_nomin.cv_results_)\n",
    "# create an excel with the cross val resutls\n",
    "df_results_clf_tree_feat_nomin.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\clf_tree_feat_nomin.xlsx',index=False)\n",
    "#Fit the best estimator with the test set\n",
    "clf_tree_feat_grid_nomin.refit\n",
    "\n",
    "preds = clf_tree_feat_grid_nomin.predict(X_test_feat)\n",
    "np.mean(preds == y_test)#0.7444444444444445\n",
    "y_pred_tree_nomin=clf_tree_feat_grid_nomin.predict(X_test_feat)\n",
    "\n",
    "overall_test_results_clf_tree_feat_nomin={'clf':['clf_tree_feat_nomin'],\n",
    "                 'params':[clf_tree_feat_grid_nomin.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_tree_nomin)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_tree_nomin, average='weighted')],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_tree_nomin, average='weighted')],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_tree_nomin, average='weighted')],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_tree_nomin, pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_tree_nomin)],\n",
    "                 'mcc_test':[matthews_corrcoef(y_test, y_pred_tree)]\n",
    "    }\n",
    "#Saving results with test set to calculate interpretability measures\n",
    "df_overall_test_results_clf_tree_feat_nomin=pd.DataFrame(data=overall_test_results_clf_tree_feat_nomin)\n",
    "df_overall_test_results_clf_tree_feat_nomin.to_excel(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\overall_test_results_clf_tree_feat_nomin.xlsx',index=False)\n",
    "\n",
    "y_train.values.astype('str')\n",
    "y_train.values.astype('str')\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf_tree_feat_grid_nomin.best_estimator_, \n",
    "                  feature_names=X_train_feat.columns,  \n",
    "                  class_names=y_train.values.astype('str'),  \n",
    "                  filled=True, rounded=True,  \n",
    "                  special_characters=True,\n",
    "                   out_file=None,\n",
    "                           )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = \"png\"\n",
    "graph.render(r'C:\\Users\\mariasiouzou\\Documents\\ΣΙΟΥΖΟΥ ΜΑΡΙΑ ΠΤΥΧΙΑΚΗ\\SSIA\\GridSearchCV_results\\dt_featsel_nomin_graph')\n",
    "\n",
    "######################\n",
    "#Lets explore the feature importance of the winner model\n",
    "win_model.get_params().keys()\n",
    "\n",
    "from matplotlib import pyplot\n",
    "# plot feature importance\n",
    "from xgboost import plot_importance\n",
    "plot_importance(win_model.named_steps['clf'],importance_type='gain')\n",
    "pyplot.show()\n",
    "\n",
    "#Build the best estimator from scratch to see the feature importances\n",
    "X_train_feat_best=X_train_feat.copy()\n",
    "X_test_feat_best=X_test_feat.copy()\n",
    "X_train_feat_best.head()\n",
    "\n",
    "#Fitting the best estimator with pruned dataset and see their future importance\n",
    "#with train set\n",
    "xgboost_clf.fit(X_train_feat_best,y_train)\n",
    "plot_importance(xgboost_clf)\n",
    "pyplot.show()\n",
    "\n",
    "xgboost_clf.fit(X_train_feat_best,y_train)\n",
    "plot_importance(xgboost_clf,  importance_type='weight', xlabel='Weight',show_values=False)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "#Fitting the best estimator with the whole dataset\n",
    "# xgboost_clf.fit(X_train,y_train)\n",
    "# plot_importance(xgboost_clf)\n",
    "# pyplot.show()\n",
    "\n",
    "\n",
    "#Use Eli5 for feature importance\n",
    "import eli5\n",
    "from eli5 import show_weights\n",
    "features = np.array(X_train_feat_best.columns)\n",
    "eli5.explain_weights_xgboost(xgboost_clf, feature_names=features)\n",
    "#To see the plot printed we have to move this code to a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcec48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe3421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47152a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
